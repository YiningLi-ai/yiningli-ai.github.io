<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://likewise-stack.github.io//feed.xml" rel="self" type="application/atom+xml"/><link href="https://likewise-stack.github.io//" rel="alternate" type="text/html" hreflang="en"/><updated>2024-11-19T09:16:59+00:00</updated><id>https://likewise-stack.github.io//feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Introduction to Transformer</title><link href="https://likewise-stack.github.io//blog/2024/transformer/" rel="alternate" type="text/html" title="Introduction to Transformer"/><published>2024-11-17T00:01:00+00:00</published><updated>2024-11-17T00:01:00+00:00</updated><id>https://likewise-stack.github.io//blog/2024/transformer</id><content type="html" xml:base="https://likewise-stack.github.io//blog/2024/transformer/"><![CDATA[<p>In this seminar, we first introduced the fundamental Transformer model, the training of GPT and BERT, as well as ViT (Vision Transformer) and linear attention. Additionally, we also discussed the Mamba model.Here is the <a href="https://zhuanlan.zhihu.com/p/7264138497">lecture notes</a> and <a href="https://www.bilibili.com/video/BV1ZUUBYeE9R/?share_source=copy_web&amp;vd_source=f99c6bc416bcadef736a7eba48835b2d">vedio</a>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/transformer-480.webp 480w,/assets/img/transformer-800.webp 800w,/assets/img/transformer-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/transformer.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Transformer </div>]]></content><author><name></name></author><category term="Seminar"/><category term="Transformer"/><category term="DL"/><summary type="html"><![CDATA[The 4th Deep Learning Seminar at Lizhi Academy,XJTU]]></summary></entry><entry><title type="html">Generative Modeling by Estimating Gradients of the Data Distribution</title><link href="https://likewise-stack.github.io//blog/2023/generative-model/" rel="alternate" type="text/html" title="Generative Modeling by Estimating Gradients of the Data Distribution"/><published>2023-08-23T21:01:00+00:00</published><updated>2023-08-23T21:01:00+00:00</updated><id>https://likewise-stack.github.io//blog/2023/generative-model</id><content type="html" xml:base="https://likewise-stack.github.io//blog/2023/generative-model/"><![CDATA[<p>Itâ€™s my reading notes of Generative Modeling by Estimating Gradients of the Data Distribution. You can find it in <a href="https://zhuanlan.zhihu.com/p/651528231">Zhihu</a></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/diffusion-480.webp 480w,/assets/img/diffusion-800.webp 800w,/assets/img/diffusion-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/diffusion.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Score Matching </div>]]></content><author><name></name></author><category term="reading-notes"/><category term="diffusion"/><summary type="html"><![CDATA[Reading notes]]></summary></entry></feed>